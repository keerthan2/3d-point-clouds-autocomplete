{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import reduce\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points2pcd(points):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_path = os.path.join('..','data','dataset','heap','train','complete','heap2_6.ply')\n",
    "# pc_path = 'existing.ply'\n",
    "pcd = o3d.io.read_point_cloud(pc_path)\n",
    "# pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd, axes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_single_pcd_variant(pc_path, axis = 1, max_mode = \"max\", margin = 0.01):\n",
    "    pcd = o3d.io.read_point_cloud(pc_path)\n",
    "    pcd_pts =  np.asarray(pcd.points)\n",
    "    base_min = np.min(pcd_pts[:,axis])\n",
    "    if max_mode == \"min\":\n",
    "        if base_min < 0:\n",
    "            base_max = -margin*abs(base_min)\n",
    "        else:\n",
    "            base_max = (1+margin)*base_min\n",
    "    else:\n",
    "        base_max = abs(np.random.randn())*np.max(pcd_pts[:,axis])\n",
    "    base_idx = np.where((pcd_pts[:,axis] >= base_min) & (pcd_pts[:,axis] <= base_max))[0]\n",
    "    base_pts = pcd_pts[base_idx,:]\n",
    "\n",
    "    mean_x, std_x = np.random.randint(low=1,high=16)*np.mean(base_pts[:,0]), max(0.5,abs(0.5*np.random.randn()))*np.std(base_pts[:,0])\n",
    "    mean_y, std_y = np.random.randint(low=1,high=16)*np.mean(base_pts[:,1]), max(0.2,abs(0.5*np.random.randn())*np.std(base_pts[:,1]))\n",
    "    mean_z, std_z = np.random.randint(low=1,high=3)*np.mean(base_pts[:,2]), max(0.05,abs(0.5*np.random.randn()))*np.std(base_pts[:,2])\n",
    "\n",
    "    noise_x = 0 + mean_x + std_x*np.random.randn(base_pts[:,0].shape[0])\n",
    "    noise_y = 0 + mean_y + std_z*np.random.randn(base_pts[:,0].shape[0])\n",
    "    noise_z = 0 #+ mean_z + std_z*np.random.randn(base_pts[:,0].shape[0])\n",
    "\n",
    "    base_pts_noise = np.zeros_like(base_pts)\n",
    "    base_pts_noise[:,0] =  base_pts[:,0] + noise_x\n",
    "    base_pts_noise[:,1] =  base_pts[:,1] + noise_y\n",
    "    base_pts_noise[:,2] =  base_pts[:,2] + noise_z\n",
    "\n",
    "    pcd_pts[base_idx,:] = base_pts_noise\n",
    "    pcd_noise = o3d.geometry.PointCloud()\n",
    "    pcd_noise.points = o3d.utility.Vector3dVector(pcd_pts)\n",
    "    \n",
    "    return pcd_noise\n",
    "\n",
    "def gen_pcd_variants(pc_path, num_variants = 5, axis = 1, max_mode = \"max\", margin = 0.01):\n",
    "    pcd_variants = []\n",
    "    for i in range(num_variants):\n",
    "        pcd_variant = gen_single_pcd_variant(pc_path, axis = axis, max_mode = max_mode, margin = margin)\n",
    "        pcd_variants.append(pcd_variant)\n",
    "    return pcd_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_path = os.path.join('..','data','dataset','heap','train','complete','heap2.ply')\n",
    "test_pcd = gen_single_pcd_variant(pc_path, axis = 1, max_mode = \"max\", margin = 0.8)\n",
    "o3d.visualization.draw_geometries([test_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_path = os.path.join('..','data','dataset','heap','train','complete','heap2.ply')\n",
    "num_variants = 10\n",
    "max_mode = \"max\" # \"max\" or \"min\"\n",
    "margin = 0.01 #between 0 and 1\n",
    "axis = 1\n",
    "pcd_variants = gen_pcd_variants(pc_path, num_variants, axis, max_mode, margin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = f\"{os.sep}\".join(pc_path.split(os.sep)[:-1])\n",
    "fname = pc_path.split(os.sep)[-1]\n",
    "for i in range(num_variants):\n",
    "    variant_fname = f\"{fname.split('.')[0]}_{i}.{fname.split('.')[1]}\"\n",
    "    save_path = os.path.join(dir_path, variant_fname)\n",
    "    o3d.io.write_point_cloud(save_path, pcd_variants[i])\n",
    "    # o3d.visualization.draw_geometries([pcd_variants[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pc_var_path = os.path.join('..','data','dataset','heap','train','complete','heap_7.ply')\n",
    "test_pcd_var = o3d.io.read_point_cloud(test_pc_var_path)\n",
    "o3d.visualization.draw_geometries([test_pcd_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(pcd, eps=0.2, min_points=10, remove_noise=True, show_pcd=True):\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=0.2, min_points=10, print_progress=False))\n",
    "    max_label = labels.max()\n",
    "    # print(f\"point cloud has {max_label + 1} clusters\")\n",
    "    pcd_points = pcd.points\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "    if remove_noise:\n",
    "        noise_idx = labels[np.where(labels < 0)[0]]\n",
    "        labels = np.delete(labels, noise_idx)\n",
    "        colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "        pcd_points_modified = np.delete(pcd_points, noise_idx, axis=0)\n",
    "    else:\n",
    "        pcd_points_modified = pcd_points\n",
    "        colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "        colors[labels < 0] = 0\n",
    "    pcd_mod = o3d.geometry.PointCloud()\n",
    "    pcd_mod.points = o3d.utility.Vector3dVector(pcd_points_modified)\n",
    "    pcd_mod.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    if show_pcd:\n",
    "        o3d.visualization.draw_geometries([pcd_mod])\n",
    "    return pcd_mod, labels\n",
    "\n",
    "def shifter(source, target, axis):\n",
    "    sp, tp = source[:,axis], target[:,axis]\n",
    "    max_sp, max_tp = np.max(sp), np.max(tp)\n",
    "    min_sp, min_tp = np.min(sp), np.min(tp)\n",
    "    if( max_tp <= min_sp) or (min_sp <= max_tp <= max_sp):\n",
    "        t = np.max(sp) - np.max(tp)\n",
    "    elif (max_sp <= min_tp) or (min_sp <= min_tp <= max_sp):\n",
    "        t = np.min(sp) - np.min(tp)\n",
    "    else:\n",
    "        t = 0\n",
    "    return t\n",
    "    \n",
    "def cluster_join(pc_path, pc_len_thresh = 100000, remove_noise=True, show_pcd=True):\n",
    "    pcd = o3d.io.read_point_cloud(pc_path)\n",
    "    if len(np.asarray(pcd.points)) > pc_len_thresh:\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "    pcd_clustered, labels = find_clusters(pcd, eps=0.2, min_points=10, remove_noise=remove_noise, show_pcd=show_pcd)\n",
    "    if labels.max() == 1:\n",
    "        points = np.asarray(pcd_clustered.points)\n",
    "        cluster_0, cluster_1 = points[np.where(labels==0)[0],:], points[np.where(labels==1)[0],:]\n",
    "        if len(cluster_0) < len(cluster_1):\n",
    "            cluster_0, cluster_1 = cluster_1, cluster_0\n",
    "        translation_vec = np.asarray([shifter(cluster_1, cluster_0, 0),shifter(cluster_1, cluster_0, 1),0])\n",
    "        new_cluster_1 = cluster_1 - translation_vec\n",
    "        joint_cluster = np.vstack((cluster_0, new_cluster_1))\n",
    "        joint_pcd = points2pcd(joint_cluster)\n",
    "    elif labels.max() == 0:\n",
    "        joint_pcd = pcd\n",
    "    else:\n",
    "        print(f\"Number of clusters = {labels.max()+1}. Returned original point cloud for {pc_path}\")\n",
    "        joint_pcd = pcd\n",
    "    return joint_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_path = os.path.join('..','data','dataset','heap','train','complete','heap2_6.ply')\n",
    "joint_pcd = cluster_join(pc_path, pc_len_thresh = 100000, remove_noise=True, show_pcd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plyfile import quick_save_ply_file, load_ply\n",
    "\n",
    "pc_dir_path = os.path.join('..','data','dataset','heap','train','complete')\n",
    "pc_save_dir_path = os.path.join('..','data','dataset','heap','train','complete_processed')\n",
    "# files = os.listdir(pc_dir_path)\n",
    "# for i in tqdm(range(len(files))):\n",
    "for f in tqdm(os.listdir(pc_dir_path)):\n",
    "    pc_path = os.path.join(pc_dir_path, f)\n",
    "    try:\n",
    "        joint_pcd = cluster_join(pc_path, pc_len_thresh = 100000, remove_noise=True, show_pcd=False)\n",
    "        quick_save_ply_file(joint_pcd.points, os.path.join(pc_save_dir_path, f))\n",
    "    except:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([joint_pcd])\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paritioning into Existing and Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperPlane(object):\n",
    "\n",
    "    def __init__(self, params, bias):\n",
    "        self.params = params\n",
    "        self.bias = bias\n",
    "\n",
    "    def check_point(self, point):\n",
    "        return np.sign(np.dot(point, self.params) + self.bias)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_plane_from_3_points(points):\n",
    "        cp = np.cross(points[1] - points[0], points[2] - points[0])\n",
    "        return HyperPlane(cp, np.dot(cp, points[0]))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_plane():\n",
    "        return HyperPlane.get_plane_from_3_points(np.random.rand(3, 3))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Plane A={}, B={}, C={}, D={}\".format(*self.params, self.bias)\n",
    "\n",
    "\n",
    "class SlicedDatasetGenerator(object):\n",
    "    @staticmethod\n",
    "    def generate_item(points,  target_partition_points_lb=1024, target_partition_points_ub=2048):\n",
    "        while True:\n",
    "            under = HyperPlane.get_random_plane().check_point(points) > 0\n",
    "            points_under_plane = points[under]\n",
    "            points_above_plane = points[~under]\n",
    "\n",
    "            if target_partition_points_ub >= len(points_under_plane) >= target_partition_points_lb:\n",
    "                return points_under_plane, points_above_plane\n",
    "            if target_partition_points_ub >= len(points_above_plane) >= target_partition_points_lb:\n",
    "                return points_above_plane, points_under_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plyfile import quick_save_ply_file, load_ply\n",
    "\n",
    "pc_dir_path = os.path.join('..','data','dataset','heap','train','complete_processed')\n",
    "part_save_dir_path = os.path.join('..','data','dataset','heap','train')\n",
    "num_part_variants = 10\n",
    "for f in tqdm(os.listdir(pc_dir_path)):\n",
    "    pc_path = os.path.join(pc_dir_path, f)\n",
    "    complete = load_ply(pc_path)\n",
    "    for npv in range(num_part_variants):\n",
    "        existing, missing = SlicedDatasetGenerator.generate_item(complete, \n",
    "                            target_partition_points_lb=10000, target_partition_points_ub = 50000)\n",
    "        f_save = f\"{f.split('.')[0]}_{npv}.{f.split('.')[1]}\"\n",
    "        quick_save_ply_file(complete, os.path.join(part_save_dir_path, 'complete', f_save))\n",
    "        quick_save_ply_file(existing, os.path.join(part_save_dir_path, 'existing', f_save))\n",
    "        quick_save_ply_file(missing, os.path.join(part_save_dir_path, 'missing', f_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_save_dir_path = os.path.join('..','data','dataset','custom','train')\n",
    "fname = 'heap_2_9.ply'\n",
    "test_epc_path = os.path.join(part_save_dir_path, 'existing', fname)\n",
    "test_mpc_path = os.path.join(part_save_dir_path, 'missing', fname)\n",
    "\n",
    "epcd = o3d.io.read_point_cloud(test_epc_path)\n",
    "epcd.paint_uniform_color([0.1, 0.706, 0]) # green\n",
    "mpcd = o3d.io.read_point_cloud(test_mpc_path)\n",
    "mpcd.paint_uniform_color([1, 0.706, 0]) # yellow\n",
    "o3d.visualization.draw_geometries([epcd,mpcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def perform_icp(source_pts, target_pts, threshold = 0.02):\n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(source_pts)\n",
    "\n",
    "    target = o3d.geometry.PointCloud()\n",
    "    target.points = o3d.utility.Vector3dVector(target_pts)\n",
    "\n",
    "    trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                            [-0.139, 0.967, -0.215, 0.7],\n",
    "                            [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "    draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation_vec = cluster_1[np.where(cluster_1==np.min(cluster_1[:,0]))[0][0],:] - cluster_0[np.where(cluster_0==np.max(cluster_0[:,0]))[0][0],:]\n",
    "# # translation_vec[0] = 0\n",
    "# translation_vec[2] = 0\n",
    "\n",
    "# print(f\"cluster_0 limits in X: [{np.min(cluster_0[:,0])},{np.max(cluster_0[:,0])}]\")\n",
    "# print(f\"cluster_1 limits in X: [{np.min(cluster_1[:,0])},{np.max(cluster_1[:,0])}]\")\n",
    "# print(f\"max(c1) > max(c2) > min(c1) => Required subraction in X of c1: {np.max(cluster_1[:,0]) - np.max(cluster_0[:,0])}\")\n",
    "# Xt_c1 = np.max(cluster_1[:,0]) - np.max(cluster_0[:,0])\n",
    "# print(\"===============================\")\n",
    "# print(f\"cluster_0 limits in Y: [{np.min(cluster_0[:,1])},{np.max(cluster_0[:,1])}]\")\n",
    "# print(f\"cluster_1 limits in Y: [{np.min(cluster_1[:,1])},{np.max(cluster_1[:,1])}]\")\n",
    "# print(f\"min(c1) > max(c2) => Required subraction in Y of c1: {np.min(cluster_1[:,1]) - np.max(cluster_0[:,1])}\")\n",
    "# Yt_c1 = np.min(cluster_1[:,1]) - np.max(cluster_0[:,1])\n",
    "# print(\"===============================\")\n",
    "# print(f\"Final translation vector to be substracted from c1: [{Xt_c1},{Yt_c1},0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3791ab1f367e35806cd16f76b036a5d685685d81b7c1c68295fd30b1e69059e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8  ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "e5c09e82eeea23e1eb2e11af75129d90fb127b749361cdb6a70b02f2395b7223"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
